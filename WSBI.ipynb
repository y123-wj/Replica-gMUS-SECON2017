{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Date: 2024/10/08\n",
    "\n",
    "用Dask库读取全部交通赛GPS数据，高效处理：\n",
    "1. 格式转换（包括日期），\n",
    "2. 定义栅格化函数，对离散GPS点进行集计处理，统计每个网格的数据点数量，选择前13个最多出租车数量的栅格\n",
    "3. 为这13个栅格指定POI编号，将POI信息合并回原始数据，使用suffixes参数避免重复列名\n",
    "4. 计算每两个相邻POI的耗时，输出格式：出租车ID  起点（POI）  终点（POI） 耗时（分钟）\n",
    "5. 将结果保存为CSV文件\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 系统\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "import platform\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# 进度条\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 数学计算\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "# GPS数据读取&处理\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import transbigdata as tbd\n",
    "# tbd.set_mapboxtoken(os.getenv('MAPBOX_TOKEN'))\n",
    "from shapely.geometry import Polygon\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "# 并行计算\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "\n",
    "# 绘图\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "# sns.set_context('notebook')\n",
    "# sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "# plt.style.use(['grid'])\n",
    "\n",
    "# 设置字体（兼容Windows和Mac OS）\n",
    "if platform.system() == 'Windows':\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "else:\n",
    "    plt.rcParams['font.family'] = ['Arial Unicode MS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 3.40 ss\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>出租车ID</th>\n",
       "      <th>纬度</th>\n",
       "      <th>经度</th>\n",
       "      <th>载客状态</th>\n",
       "      <th>时间点</th>\n",
       "      <th>经度索引</th>\n",
       "      <th>纬度索引</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30.624806</td>\n",
       "      <td>104.136604</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 21:18:46</td>\n",
       "      <td>83</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30.624809</td>\n",
       "      <td>104.136612</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 21:18:15</td>\n",
       "      <td>83</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>30.624811</td>\n",
       "      <td>104.136587</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 21:20:17</td>\n",
       "      <td>83</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30.624811</td>\n",
       "      <td>104.136596</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 21:19:16</td>\n",
       "      <td>83</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>30.624811</td>\n",
       "      <td>104.136619</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 21:17:44</td>\n",
       "      <td>83</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   出租车ID         纬度          经度  载客状态                 时间点  经度索引  纬度索引\n",
       "0      1  30.624806  104.136604     1 2014-08-03 21:18:46    83    37\n",
       "1      1  30.624809  104.136612     1 2014-08-03 21:18:15    83    37\n",
       "2      1  30.624811  104.136587     1 2014-08-03 21:20:17    83    37\n",
       "3      1  30.624811  104.136596     1 2014-08-03 21:19:16    83    37\n",
       "4      1  30.624811  104.136619     1 2014-08-03 21:17:44    83    37"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文件路径列表（不止一个文件）\n",
    "directory = r\"E:\\taxi_data\\gps_data\\gps_1\"\n",
    "file_list = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "\n",
    "# 读取文件\n",
    "ddf = dd.read_csv(file_list, header=None,\n",
    "                   names=['出租车ID', '纬度', '经度', '载客状态', '时间点'])\n",
    "\n",
    "# 格式转换\n",
    "ddf['出租车ID'] = ddf['出租车ID'].astype(int)\n",
    "ddf['纬度'] = ddf['纬度'].astype(float)\n",
    "ddf['经度'] = ddf['经度'].astype(float)\n",
    "ddf['时间点'] = dd.to_datetime(ddf['时间点'])\n",
    "\n",
    "# 栅格化\n",
    "grid_size = 1000\n",
    "earth_radius = 6371004\n",
    "min_lat, max_lat, min_lon, max_lon = (30.290675, 31.032468, 103.269638, 104.609693)\n",
    "delta_lat = grid_size * 360 / (2 * math.pi * earth_radius)\n",
    "delta_lon = grid_size * 360 / (2 * math.pi * earth_radius * math.cos((min_lat + max_lat) * math.pi / 360))\n",
    "ddf['经度索引'] = ((ddf['经度'] - (min_lon - delta_lon / 2)) / delta_lon).astype('int')\n",
    "ddf['纬度索引'] = ((ddf['纬度'] - (min_lat - delta_lat / 2)) / delta_lat).astype('int')\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>经度索引</th>\n",
       "      <th>纬度索引</th>\n",
       "      <th>count</th>\n",
       "      <th>辅助列</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>40</td>\n",
       "      <td>24451946</td>\n",
       "      <td>76_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>40</td>\n",
       "      <td>18683562</td>\n",
       "      <td>77_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>41</td>\n",
       "      <td>18039878</td>\n",
       "      <td>77_41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>42</td>\n",
       "      <td>15756466</td>\n",
       "      <td>76_42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>31</td>\n",
       "      <td>14886638</td>\n",
       "      <td>66_31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78</td>\n",
       "      <td>41</td>\n",
       "      <td>14834008</td>\n",
       "      <td>78_41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>72</td>\n",
       "      <td>40</td>\n",
       "      <td>14637176</td>\n",
       "      <td>72_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>76</td>\n",
       "      <td>41</td>\n",
       "      <td>14120298</td>\n",
       "      <td>76_41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79</td>\n",
       "      <td>37</td>\n",
       "      <td>12692081</td>\n",
       "      <td>79_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>78</td>\n",
       "      <td>40</td>\n",
       "      <td>12496950</td>\n",
       "      <td>78_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>73</td>\n",
       "      <td>38</td>\n",
       "      <td>12294001</td>\n",
       "      <td>73_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>76</td>\n",
       "      <td>37</td>\n",
       "      <td>12287876</td>\n",
       "      <td>76_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>77</td>\n",
       "      <td>42</td>\n",
       "      <td>12136517</td>\n",
       "      <td>77_42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    经度索引  纬度索引     count    辅助列\n",
       "0     76    40  24451946  76_40\n",
       "1     77    40  18683562  77_40\n",
       "2     77    41  18039878  77_41\n",
       "3     76    42  15756466  76_42\n",
       "4     66    31  14886638  66_31\n",
       "5     78    41  14834008  78_41\n",
       "6     72    40  14637176  72_40\n",
       "7     76    41  14120298  76_41\n",
       "8     79    37  12692081  79_37\n",
       "9     78    40  12496950  78_40\n",
       "10    73    38  12294001  73_38\n",
       "11    76    37  12287876  76_37\n",
       "12    77    42  12136517  77_42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取栅格化后的数据并降序排列13个POI\n",
    "df_grid = pd.read_csv('df_grid_computed.csv')\n",
    "pois = df_grid.sort_values(by='count', ascending=False).nlargest(n=13, columns=['count']).reset_index(drop=True)\n",
    "pois['辅助列'] = pois['经度索引'].astype(str) + '_' + pois['纬度索引'].astype(str)\n",
    "pois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "删除POI-Free数据，转换为分钟\n",
    "\n",
    "对于每个出租车ID, 执行计算逻辑\n",
    "\n",
    "如果下一个POI和上一个POI相异，添加一条记录，计算每两个相邻POI的耗时，输出格式：[出租车ID  起点（POI）  终点（POI） 耗时（分钟）]\n",
    "创建辅助列以标识POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 994.93 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>出租车ID</th>\n",
       "      <th>纬度</th>\n",
       "      <th>经度</th>\n",
       "      <th>载客状态</th>\n",
       "      <th>时间点</th>\n",
       "      <th>经度索引</th>\n",
       "      <th>纬度索引</th>\n",
       "      <th>辅助列</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30.624806</td>\n",
       "      <td>104.136604</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 21:18:46</td>\n",
       "      <td>83</td>\n",
       "      <td>37</td>\n",
       "      <td>83_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30.624809</td>\n",
       "      <td>104.136612</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 21:18:15</td>\n",
       "      <td>83</td>\n",
       "      <td>37</td>\n",
       "      <td>83_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>30.624811</td>\n",
       "      <td>104.136587</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 21:20:17</td>\n",
       "      <td>83</td>\n",
       "      <td>37</td>\n",
       "      <td>83_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30.624811</td>\n",
       "      <td>104.136596</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 21:19:16</td>\n",
       "      <td>83</td>\n",
       "      <td>37</td>\n",
       "      <td>83_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>30.624811</td>\n",
       "      <td>104.136619</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 21:17:44</td>\n",
       "      <td>83</td>\n",
       "      <td>37</td>\n",
       "      <td>83_37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   出租车ID         纬度          经度  载客状态                 时间点  经度索引  纬度索引    辅助列\n",
       "0      1  30.624806  104.136604     1 2014-08-03 21:18:46    83    37  83_37\n",
       "1      1  30.624809  104.136612     1 2014-08-03 21:18:15    83    37  83_37\n",
       "2      1  30.624811  104.136587     1 2014-08-03 21:20:17    83    37  83_37\n",
       "3      1  30.624811  104.136596     1 2014-08-03 21:19:16    83    37  83_37\n",
       "4      1  30.624811  104.136619     1 2014-08-03 21:17:44    83    37  83_37"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建辅助列\n",
    "# 列出原始数据出租车辅助列编号，方便后续与13个POI编号进行对比\n",
    "ddf['辅助列'] = ddf['经度索引'].astype(str) + '_' + ddf['纬度索引'].astype(str)\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POI编号</th>\n",
       "      <th>经度索引</th>\n",
       "      <th>纬度索引</th>\n",
       "      <th>count</th>\n",
       "      <th>辅助列</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>40</td>\n",
       "      <td>24451946</td>\n",
       "      <td>76_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>40</td>\n",
       "      <td>18683562</td>\n",
       "      <td>77_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>41</td>\n",
       "      <td>18039878</td>\n",
       "      <td>77_41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>42</td>\n",
       "      <td>15756466</td>\n",
       "      <td>76_42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>31</td>\n",
       "      <td>14886638</td>\n",
       "      <td>66_31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   POI编号  经度索引  纬度索引     count    辅助列\n",
       "0      1    76    40  24451946  76_40\n",
       "1      2    77    40  18683562  77_40\n",
       "2      3    77    41  18039878  77_41\n",
       "3      4    76    42  15756466  76_42\n",
       "4      5    66    31  14886638  66_31"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取13个最热门POI\n",
    "poi_df = pd.read_csv('poi.csv')\n",
    "\n",
    "# 创建POI列表并计数\n",
    "POI = poi_df.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "POI['辅助列'] = POI['经度索引'].astype(str) + '_' + POI['纬度索引'].astype(str)\n",
    "POI.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 2.40 ss\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>出租车ID</th>\n",
       "      <th>纬度</th>\n",
       "      <th>经度</th>\n",
       "      <th>载客状态</th>\n",
       "      <th>时间点</th>\n",
       "      <th>经度索引</th>\n",
       "      <th>纬度索引</th>\n",
       "      <th>辅助列</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>2</td>\n",
       "      <td>30.619336</td>\n",
       "      <td>104.067111</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 21:57:18</td>\n",
       "      <td>76</td>\n",
       "      <td>37</td>\n",
       "      <td>76_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>2</td>\n",
       "      <td>30.619658</td>\n",
       "      <td>104.066771</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 20:52:34</td>\n",
       "      <td>76</td>\n",
       "      <td>37</td>\n",
       "      <td>76_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>2</td>\n",
       "      <td>30.619698</td>\n",
       "      <td>104.067447</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 21:57:28</td>\n",
       "      <td>76</td>\n",
       "      <td>37</td>\n",
       "      <td>76_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>2</td>\n",
       "      <td>30.619743</td>\n",
       "      <td>104.068535</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 21:57:38</td>\n",
       "      <td>76</td>\n",
       "      <td>37</td>\n",
       "      <td>76_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>2</td>\n",
       "      <td>30.620093</td>\n",
       "      <td>104.066735</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 20:52:24</td>\n",
       "      <td>76</td>\n",
       "      <td>37</td>\n",
       "      <td>76_37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      出租车ID         纬度          经度  载客状态                 时间点  经度索引  纬度索引  \\\n",
       "2871      2  30.619336  104.067111     1 2014-08-03 21:57:18    76    37   \n",
       "2878      2  30.619658  104.066771     1 2014-08-03 20:52:34    76    37   \n",
       "2880      2  30.619698  104.067447     1 2014-08-03 21:57:28    76    37   \n",
       "2881      2  30.619743  104.068535     1 2014-08-03 21:57:38    76    37   \n",
       "2898      2  30.620093  104.066735     1 2014-08-03 20:52:24    76    37   \n",
       "\n",
       "        辅助列  \n",
       "2871  76_37  \n",
       "2878  76_37  \n",
       "2880  76_37  \n",
       "2881  76_37  \n",
       "2898  76_37  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 过滤掉原始数据出租车不在13个POI中的数据\n",
    "filtered_ddf = ddf[ddf['辅助列'].isin(POI['辅助列'])]\n",
    "filtered_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 统计在13个POI中出租车的ID\n",
    "# unique_ids = filtered_ddf['出租车ID'].unique().compute()\n",
    "# unique_ids\n",
    "\n",
    "# # 13个POI中有多少个出租车\n",
    "# len(unique_ids)\n",
    "\n",
    "# # 统计出租车在13个POI中出现的数量\n",
    "# ids = filtered_ddf['出租车ID'].value_counts().compute()\n",
    "# ids\n",
    "\n",
    "# # 通过ids选出出现次数最多的196个出租车\n",
    "# top_196_ids = ids.nlargest(196)\n",
    "# top_196_ids.to_csv('top_196_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[################                        ] | 41% Completed | 10m 14ss"
     ]
    }
   ],
   "source": [
    "# 读取top_196_ids.csv\n",
    "top_196_ids = pd.read_csv('top_196_ids.csv')\n",
    "\n",
    "# 过滤掉不在top_196_ids中的出租车数据\n",
    "filtered_ddf = ddf[ddf['出租车ID'].isin(top_196_ids['出租车ID'])]\n",
    "\n",
    "# 按出租车ID和时间排序\n",
    "filtered_ddf = filtered_ddf.sort_values(['出租车ID', '时间点'])\n",
    "\n",
    "# 转换时间格式，确保'时间点'是datetime类型\n",
    "filtered_ddf['时间点'] = dd.to_datetime(filtered_ddf['时间点'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# 计算每辆出租车的前一个POI，显式指定meta参数\n",
    "filtered_ddf['起点POI'] = filtered_ddf.groupby('出租车ID')['辅助列'].shift(1, meta=('辅助列', 'object'))\n",
    "\n",
    "# 计算每辆出租车的前一个时间，显式指定meta参数\n",
    "filtered_ddf['前一时间'] = filtered_ddf['时间点'].groupby(filtered_ddf['出租车ID']).shift(1, meta=('时间点', 'datetime64[ns]'))\n",
    "\n",
    "# 筛选出POI变化的记录\n",
    "transitions = filtered_ddf[filtered_ddf['辅助列'] != filtered_ddf['起点POI']].copy()\n",
    "\n",
    "# 计算转换之间的耗时（分钟）\n",
    "transitions['耗时（分钟）'] = (transitions['时间点'] - transitions['前一时间']).dt.total_seconds() / 60.0\n",
    "\n",
    "# 构建结果数据框\n",
    "results_df = transitions[['出租车ID', '起点POI', '辅助列', '耗时（分钟）']].rename(columns={'辅助列': '终点POI'})\n",
    "\n",
    "# 显示结果\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 2.67 ss\n",
      "[########################################] | 100% Completed | 2.76 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\y\\AppData\\Local\\Temp\\ipykernel_5864\\2864449081.py:12: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  filtered_ddf['前一时间'] = dd.to_datetime(filtered_ddf['时间点'], format='%Y-%m-%d %H:%M:%S').groupby(filtered_ddf['出租车ID']).shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 1% Completed | 266.45 ss\n",
      "[                                        ] | 1% Completed | 266.83 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m transitions \u001b[38;5;241m=\u001b[39m filtered_ddf[filtered_ddf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m辅助列\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m filtered_ddf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m起点POI\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 计算耗时（分钟）\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m transitions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m耗时（分钟）\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (pd\u001b[38;5;241m.\u001b[39mto_datetime(transitions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m时间点\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m-\u001b[39m transitions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m前一时间\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtotal_seconds() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60.0\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 构建结果DataFrame\u001b[39;00m\n\u001b[0;32m     22\u001b[0m results_df \u001b[38;5;241m=\u001b[39m transitions[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m出租车ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m起点POI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m辅助列\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m耗时（分钟）\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m辅助列\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m终点POI\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1086\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_maybe_cache\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;66;03m# \"Union[float, str, datetime, List[Any], Tuple[Any, ...], ExtensionArray,\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m     \u001b[38;5;66;03m# ndarray[Any, Any], Series]\"; expected \"Union[List[Any], Tuple[Any, ...],\u001b[39;00m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# Union[Union[ExtensionArray, ndarray[Any, Any]], Index, Series], Series]\"\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     argc \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1084\u001b[0m         Union[\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, ExtensionArray, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries\u001b[39m\u001b[38;5;124m\"\u001b[39m, Index], arg\n\u001b[0;32m   1085\u001b[0m     )\n\u001b[1;32m-> 1086\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m _maybe_cache(argc, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutOfBoundsDatetime:\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;66;03m# caching attempts to create a DatetimeIndex, which may raise\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;66;03m# an OOB. If that's the desired behavior, then just reraise...\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:239\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    235\u001b[0m cache_array \u001b[38;5;241m=\u001b[39m Series(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# Perform a quicker unique check\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_cache(arg):\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cache_array\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (np\u001b[38;5;241m.\u001b[39mndarray, ExtensionArray, Index, ABCSeries)):\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:183\u001b[0m, in \u001b[0;36mshould_cache\u001b[1;34m(arg, unique_share, check_count)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# default realization\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_count \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;66;03m# in this case, the gain from caching is negligible\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(arg) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m start_caching_at:\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(arg) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_collection.py:382\u001b[0m, in \u001b[0;36mFrameBase.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_collection(Len(\u001b[38;5;28mself\u001b[39m))\u001b[38;5;241m.\u001b[39mcompute()\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_collection.py:476\u001b[0m, in \u001b[0;36mFrameBase.compute\u001b[1;34m(self, fuse, **kwargs)\u001b[0m\n\u001b[0;32m    474\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mrepartition(npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    475\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse)\n\u001b[1;32m--> 476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DaskMethodsMixin\u001b[38;5;241m.\u001b[39mcompute(out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask\\base.py:375\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    352\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 375\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m compute(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask\\base.py:661\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 661\u001b[0m     results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask\\diagnostics\\progress.py:106\u001b[0m, in \u001b[0;36mProgressBar._pretask\u001b[1;34m(self, key, dsk, state)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m=\u001b[39m state\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\ipykernel\\iostream.py:578\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[1;32m--> 578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_timeout):\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mTrue\u001b[39;00m, timeout)\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "top_196_ids = pd.read_csv('top_196_ids.csv')\n",
    "# 过滤掉原始数据出租车不在13个POI中的数据\n",
    "filtered_ddf = ddf[ddf['出租车ID'].isin(top_196_ids['出租车ID'])]\n",
    "filtered_ddf.head()\n",
    "\n",
    "# 按出租车ID和时间排序\n",
    "filtered_ddf = filtered_ddf.sort_values(['出租车ID', '时间点'])\n",
    "\n",
    "# 计算前一个POI和时间\n",
    "filtered_ddf['起点POI'] = filtered_ddf.groupby('出租车ID')['辅助列'].shift(1, meta=('辅助列', 'object'))\n",
    "\n",
    "filtered_ddf['前一时间'] = dd.to_datetime(filtered_ddf['时间点'], format='%Y-%m-%d %H:%M:%S').groupby(filtered_ddf['出租车ID']).shift(1)\n",
    "\n",
    "\n",
    "# 筛选POI变化的记录\n",
    "transitions = filtered_ddf[filtered_ddf['辅助列'] != filtered_ddf['起点POI']].copy()\n",
    "\n",
    "# 计算耗时（分钟）\n",
    "transitions['耗时（分钟）'] = (pd.to_datetime(transitions['时间点']) - transitions['前一时间']).dt.total_seconds() / 60.0\n",
    "\n",
    "# 构建结果DataFrame\n",
    "results_df = transitions[['出租车ID', '起点POI', '辅助列', '耗时（分钟）']].rename(columns={'辅助列': '终点POI'})\n",
    "\n",
    "# 显示结果\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[###############################         ] | 79% Completed | 23m 46ss"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:1455: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[################################        ] | 80% Completed | 23m 55s\n",
      "[################################        ] | 80% Completed | 23m 55s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m results_df \u001b[38;5;241m=\u001b[39m transitions[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m出租车ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m起点POI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m辅助列\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m耗时（分钟）\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m辅助列\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m终点POI\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# 显示结果\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_collection.py:702\u001b[0m, in \u001b[0;36mFrameBase.head\u001b[1;34m(self, n, npartitions, compute)\u001b[0m\n\u001b[0;32m    700\u001b[0m out \u001b[38;5;241m=\u001b[39m new_collection(expr\u001b[38;5;241m.\u001b[39mHead(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39mn, npartitions\u001b[38;5;241m=\u001b[39mnpartitions))\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute:\n\u001b[1;32m--> 702\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_collection.py:475\u001b[0m, in \u001b[0;36mFrameBase.compute\u001b[1;34m(self, fuse, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, Scalar):\n\u001b[0;32m    474\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mrepartition(npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 475\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DaskMethodsMixin\u001b[38;5;241m.\u001b[39mcompute(out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_collection.py:590\u001b[0m, in \u001b[0;36mFrameBase.optimize\u001b[1;34m(self, fuse)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, fuse: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    573\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimizes the DataFrame.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \n\u001b[0;32m    575\u001b[0m \u001b[38;5;124;03m    Runs the optimizer with all steps over the DataFrame and wraps the result in a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;124;03m        The optimized Dask Dataframe\u001b[39;00m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_collection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse))\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:94\u001b[0m, in \u001b[0;36mExpr.optimize\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m optimize(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:3028\u001b[0m, in \u001b[0;36moptimize\u001b[1;34m(expr, fuse)\u001b[0m\n\u001b[0;32m   3007\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"High level query optimization\u001b[39;00m\n\u001b[0;32m   3008\u001b[0m \n\u001b[0;32m   3009\u001b[0m \u001b[38;5;124;03mThis leverages three optimization passes:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3024\u001b[0m \u001b[38;5;124;03moptimize_blockwise_fusion\u001b[39;00m\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3026\u001b[0m stage: core\u001b[38;5;241m.\u001b[39mOptimizerStage \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fuse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimplified-physical\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 3028\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimize_until(expr, stage)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:2989\u001b[0m, in \u001b[0;36moptimize_until\u001b[1;34m(expr, stage)\u001b[0m\n\u001b[0;32m   2986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m expr\n\u001b[0;32m   2988\u001b[0m \u001b[38;5;66;03m# Lower\u001b[39;00m\n\u001b[1;32m-> 2989\u001b[0m expr \u001b[38;5;241m=\u001b[39m expr\u001b[38;5;241m.\u001b[39mlower_completely()\n\u001b[0;32m   2990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphysical\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2991\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m expr\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_core.py:436\u001b[0m, in \u001b[0;36mExpr.lower_completely\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    434\u001b[0m expr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 436\u001b[0m     new \u001b[38;5;241m=\u001b[39m expr\u001b[38;5;241m.\u001b[39mlower_once()\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m==\u001b[39m expr\u001b[38;5;241m.\u001b[39m_name:\n\u001b[0;32m    438\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_core.py:404\u001b[0m, in \u001b[0;36mExpr.lower_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m operand \u001b[38;5;129;01min\u001b[39;00m out\u001b[38;5;241m.\u001b[39moperands:\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(operand, Expr):\n\u001b[1;32m--> 404\u001b[0m         new \u001b[38;5;241m=\u001b[39m operand\u001b[38;5;241m.\u001b[39mlower_once()\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m!=\u001b[39m operand\u001b[38;5;241m.\u001b[39m_name:\n\u001b[0;32m    406\u001b[0m             changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_core.py:404\u001b[0m, in \u001b[0;36mExpr.lower_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m operand \u001b[38;5;129;01min\u001b[39;00m out\u001b[38;5;241m.\u001b[39moperands:\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(operand, Expr):\n\u001b[1;32m--> 404\u001b[0m         new \u001b[38;5;241m=\u001b[39m operand\u001b[38;5;241m.\u001b[39mlower_once()\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m!=\u001b[39m operand\u001b[38;5;241m.\u001b[39m_name:\n\u001b[0;32m    406\u001b[0m             changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_core.py:404\u001b[0m, in \u001b[0;36mExpr.lower_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m operand \u001b[38;5;129;01min\u001b[39;00m out\u001b[38;5;241m.\u001b[39moperands:\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(operand, Expr):\n\u001b[1;32m--> 404\u001b[0m         new \u001b[38;5;241m=\u001b[39m operand\u001b[38;5;241m.\u001b[39mlower_once()\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m!=\u001b[39m operand\u001b[38;5;241m.\u001b[39m_name:\n\u001b[0;32m    406\u001b[0m             changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_core.py:393\u001b[0m, in \u001b[0;36mExpr.lower_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    390\u001b[0m expr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# Lower this node\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m out \u001b[38;5;241m=\u001b[39m expr\u001b[38;5;241m.\u001b[39m_lower()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    395\u001b[0m     out \u001b[38;5;241m=\u001b[39m expr\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:2434\u001b[0m, in \u001b[0;36mHead._lower\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, BlockwiseHead):\n\u001b[0;32m   2432\u001b[0m     \u001b[38;5;66;03m# Lower to Blockwise\u001b[39;00m\n\u001b[0;32m   2433\u001b[0m     npartitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperand(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpartitions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperand(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpartitions\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mnpartitions:\n\u001b[0;32m   2435\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2436\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mnpartitions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m partitions, head received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnpartitions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2437\u001b[0m         )\n\u001b[0;32m   2438\u001b[0m     partitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partitions\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:398\u001b[0m, in \u001b[0;36mExpr.npartitions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperands[idx]\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisions) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\functools.py:995\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, instance, owner)\u001b[0m\n\u001b[0;32m    993\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[1;32m--> 995\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(instance)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    997\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:382\u001b[0m, in \u001b[0;36mExpr.divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdivisions\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_divisions())\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:529\u001b[0m, in \u001b[0;36mBlockwise._divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    527\u001b[0m dependencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependencies()\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m dependencies:\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broadcast_dep(arg):\n\u001b[0;32m    530\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mdivisions \u001b[38;5;241m==\u001b[39m dependencies[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdivisions\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dependencies[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdivisions\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:520\u001b[0m, in \u001b[0;36mBlockwise._broadcast_dep\u001b[1;34m(self, dep)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_broadcast_dep\u001b[39m(\u001b[38;5;28mself\u001b[39m, dep: Expr):\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;66;03m# Checks if a dependency should be broadcasted to\u001b[39;00m\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;66;03m# all partitions of this `Blockwise` operation\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dep\u001b[38;5;241m.\u001b[39mnpartitions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dep\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:398\u001b[0m, in \u001b[0;36mExpr.npartitions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperands[idx]\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisions) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\functools.py:995\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, instance, owner)\u001b[0m\n\u001b[0;32m    993\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[1;32m--> 995\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(instance)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    997\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:382\u001b[0m, in \u001b[0;36mExpr.divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdivisions\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_divisions())\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:3370\u001b[0m, in \u001b[0;36mMaybeAlignPartitions._divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_divisions\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 3370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m {df\u001b[38;5;241m.\u001b[39mnpartitions \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs} \u001b[38;5;241m==\u001b[39m {\u001b[38;5;241m1\u001b[39m}:\n\u001b[0;32m   3371\u001b[0m         divs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3372\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\functools.py:995\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, instance, owner)\u001b[0m\n\u001b[0;32m    993\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[1;32m--> 995\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(instance)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    997\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:3388\u001b[0m, in \u001b[0;36mMaybeAlignPartitions.args\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3385\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[0;32m   3386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   3387\u001b[0m     dfs \u001b[38;5;241m=\u001b[39m [op \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperands \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, Expr)]\n\u001b[1;32m-> 3388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [op \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m dfs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_broadcastable(dfs, op)]\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:3044\u001b[0m, in \u001b[0;36mis_broadcastable\u001b[1;34m(dfs, s)\u001b[0m\n\u001b[0;32m   3039\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   3042\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m   3043\u001b[0m     s\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 3044\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m s\u001b[38;5;241m.\u001b[39mnpartitions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3045\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m s\u001b[38;5;241m.\u001b[39mknown_divisions\n\u001b[0;32m   3046\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(compare(s, df) \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m dfs \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m   3047\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m s\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3048\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:398\u001b[0m, in \u001b[0;36mExpr.npartitions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperands[idx]\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisions) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\functools.py:995\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, instance, owner)\u001b[0m\n\u001b[0;32m    993\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[1;32m--> 995\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(instance)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    997\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:382\u001b[0m, in \u001b[0;36mExpr.divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdivisions\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_divisions())\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_groupby.py:901\u001b[0m, in \u001b[0;36mGroupByApply._divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_divisions\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneed_to_shuffle:\n\u001b[0;32m    902\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mnpartitions \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mdivisions\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\functools.py:995\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, instance, owner)\u001b[0m\n\u001b[0;32m    993\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[1;32m--> 995\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(instance)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    997\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_groupby.py:926\u001b[0m, in \u001b[0;36mGroupByApply.need_to_shuffle\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    921\u001b[0m         \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_by_columns) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(cols)\n\u001b[0;32m    922\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m cols \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39munique_partition_mapping_columns_from_shuffle\n\u001b[0;32m    923\u001b[0m     ):\n\u001b[0;32m    924\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(div \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m div \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mdivisions) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    927\u001b[0m     _contains_index_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39m_meta\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname, b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mby\n\u001b[0;32m    928\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\functools.py:995\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, instance, owner)\u001b[0m\n\u001b[0;32m    993\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[1;32m--> 995\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(instance)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    997\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:382\u001b[0m, in \u001b[0;36mExpr.divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdivisions\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_divisions())\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:2067\u001b[0m, in \u001b[0;36mProjection._divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 2067\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_divisions()\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:529\u001b[0m, in \u001b[0;36mBlockwise._divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    527\u001b[0m dependencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependencies()\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m dependencies:\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broadcast_dep(arg):\n\u001b[0;32m    530\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mdivisions \u001b[38;5;241m==\u001b[39m dependencies[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdivisions\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dependencies[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdivisions\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_expr.py:520\u001b[0m, in \u001b[0;36mBlockwise._broadcast_dep\u001b[1;34m(self, dep)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_broadcast_dep\u001b[39m(\u001b[38;5;28mself\u001b[39m, dep: Expr):\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;66;03m# Checks if a dependency should be broadcasted to\u001b[39;00m\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;66;03m# all partitions of this `Blockwise` operation\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dep\u001b[38;5;241m.\u001b[39mnpartitions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dep\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_shuffle.py:752\u001b[0m, in \u001b[0;36mBaseSetIndexSortValues.npartitions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnpartitions\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperand(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpartitions\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_divisions()) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_shuffle.py:957\u001b[0m, in \u001b[0;36mSortValues._divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mnpartitions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;66;03m# Protect against triggering calculations when we only have one division\u001b[39;00m\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 957\u001b[0m divisions, mins, maxes, presorted \u001b[38;5;241m=\u001b[39m _get_divisions(\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe,\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mby[\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npartitions_input,\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_divisions_ascending,\n\u001b[0;32m    962\u001b[0m     upsample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsample,\n\u001b[0;32m    963\u001b[0m )\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m presorted:\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mdivisions\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_shuffle.py:1288\u001b[0m, in \u001b[0;36m_get_divisions\u001b[1;34m(frame, other, npartitions, ascending, partition_size, upsample)\u001b[0m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m divisions_lru:\n\u001b[0;32m   1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m divisions_lru[key]\n\u001b[1;32m-> 1288\u001b[0m result \u001b[38;5;241m=\u001b[39m _calculate_divisions(\n\u001b[0;32m   1289\u001b[0m     frame, other, npartitions, ascending, partition_size, upsample\n\u001b[0;32m   1290\u001b[0m )\n\u001b[0;32m   1291\u001b[0m divisions_lru[key] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask_expr\\_shuffle.py:1309\u001b[0m, in \u001b[0;36m_calculate_divisions\u001b[1;34m(frame, other, npartitions, ascending, partition_size, upsample)\u001b[0m\n\u001b[0;32m   1306\u001b[0m     other \u001b[38;5;241m=\u001b[39m ToSeriesIndex(other)\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1309\u001b[0m     divisions, mins, maxes \u001b[38;5;241m=\u001b[39m compute(\n\u001b[0;32m   1310\u001b[0m         new_collection(RepartitionQuantiles(other, npartitions, upsample\u001b[38;5;241m=\u001b[39mupsample)),\n\u001b[0;32m   1311\u001b[0m         new_collection(other)\u001b[38;5;241m.\u001b[39mmap_partitions(M\u001b[38;5;241m.\u001b[39mmin),\n\u001b[0;32m   1312\u001b[0m         new_collection(other)\u001b[38;5;241m.\u001b[39mmap_partitions(M\u001b[38;5;241m.\u001b[39mmax),\n\u001b[0;32m   1313\u001b[0m     )\n\u001b[0;32m   1314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m# When there are nulls and a column is non-numeric, a TypeError is sometimes raised as a result of\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;66;03m# 1) computing mins/maxes above, 2) every null being switched to NaN, and 3) NaN being a float.\u001b[39;00m\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;66;03m# Also, Pandas ExtensionDtypes may cause TypeErrors when dealing with special nulls such as pd.NaT or pd.NA.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;66;03m# If this happens, we hint the user about eliminating nulls beforehand.\u001b[39;00m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_numeric_dtype(other\u001b[38;5;241m.\u001b[39m_meta\u001b[38;5;241m.\u001b[39mdtype):\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask\\base.py:661\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 661\u001b[0m     results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\dask\\diagnostics\\progress.py:106\u001b[0m, in \u001b[0;36mProgressBar._pretask\u001b[1;34m(self, key, dsk, state)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m=\u001b[39m state\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\ipykernel\\iostream.py:578\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[1;32m--> 578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_timeout):\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mTrue\u001b[39;00m, timeout)\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 读取top_196_ids.csv\n",
    "top_196_ids = pd.read_csv('top_196_ids.csv')\n",
    "\n",
    "# 过滤掉不在top_196_ids中的出租车数据\n",
    "filtered_ddf = ddf[ddf['出租车ID'].isin(top_196_ids['出租车ID'])]\n",
    "\n",
    "# 转换时间格式，明确指定日期格式，并处理无效日期（errors='coerce' 会将无效日期设置为 NaT）\n",
    "filtered_ddf['时间点'] = dd.to_datetime(filtered_ddf['时间点'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "# 删除包含无效日期（NaT）的行\n",
    "filtered_ddf = filtered_ddf.dropna(subset=['时间点'])\n",
    "\n",
    "# 按出租车ID和时间排序\n",
    "filtered_ddf = filtered_ddf.sort_values(['出租车ID', '时间点'])\n",
    "\n",
    "# 计算每辆出租车的前一个POI，显式指定meta参数\n",
    "filtered_ddf['起点POI'] = filtered_ddf.groupby('出租车ID')['辅助列'].shift(1, meta=('辅助列', 'object'))\n",
    "\n",
    "# 计算每辆出租车的前一个时间，显式指定meta参数\n",
    "filtered_ddf['前一时间'] = filtered_ddf['时间点'].groupby(filtered_ddf['出租车ID']).shift(1, meta=('时间点', 'datetime64[ns]'))\n",
    "\n",
    "# 筛选出POI变化的记录\n",
    "transitions = filtered_ddf[filtered_ddf['辅助列'] != filtered_ddf['起点POI']].copy()\n",
    "\n",
    "# 计算转换之间的耗时（分钟）\n",
    "transitions['耗时（分钟）'] = (transitions['时间点'] - transitions['前一时间']).dt.total_seconds() / 60.0\n",
    "\n",
    "# 构建结果数据框\n",
    "results_df = transitions[['出租车ID', '起点POI', '辅助列', '耗时（分钟）']].rename(columns={'辅助列': '终点POI'})\n",
    "\n",
    "# 显示结果\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   出租车ID  起点POI  终点POI      耗时（分钟）  count\n",
      "0      2  76_37  79_37   70.216667    140\n",
      "1      2  76_37  79_37   81.933333    140\n",
      "2      2  79_37  73_38  422.200000      8\n",
      "3      2  72_40  77_40   57.183333    158\n",
      "4      2  77_40  72_40  323.616667    152\n"
     ]
    }
   ],
   "source": [
    "# 增加起点POI和终点POI相同的数据的次数 count\n",
    "results_df['count'] = results_df.groupby(['起点POI', '终点POI'])['出租车ID'].transform('count')\n",
    "\n",
    "# 显示增加 count 列后的结果\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    出租车ID  起点POI  终点POI     耗时（分钟）\n",
      "3       2  72_40  77_40  57.183333\n",
      "5       2  77_40  76_40  38.133333\n",
      "7       2  76_40  77_40  19.366667\n",
      "8       2  72_40  77_40  51.316667\n",
      "12      2  77_40  76_40  46.816667\n"
     ]
    }
   ],
   "source": [
    "# 只保留刚刚耗时小于等于60分钟的数据\n",
    "filtered_results_df = results_df[results_df['耗时（分钟）'] <= 60]\n",
    "\n",
    "# 显示过滤后的结果\n",
    "print(filtered_results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    出租车ID  起点POI  终点POI     耗时（分钟）  count\n",
      "3       2  72_40  77_40  57.183333     23\n",
      "5       2  77_40  76_40  38.133333     52\n",
      "7       2  76_40  77_40  19.366667     56\n",
      "8       2  72_40  77_40  51.316667     23\n",
      "12      2  77_40  76_40  46.816667     52\n"
     ]
    }
   ],
   "source": [
    "# 增加起点POI和终点POI相同的数据的次数 count\n",
    "filtered_results_df.loc[:, 'count'] = filtered_results_df.groupby(['起点POI', '终点POI'])['出租车ID'].transform('count')\n",
    "\n",
    "# 显示增加 count 列后的结果\n",
    "print(filtered_results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   起点POI  终点POI  filtered_count  total_count  Z(i,j,T)\n",
      "0  66_31  76_37               2            7  0.285714\n",
      "1  72_40  76_40              11          127  0.086614\n",
      "2  72_40  77_40              23          158  0.145570\n",
      "3  72_40  78_40               4           68  0.058824\n",
      "4  76_37  73_38               1            5  0.200000\n"
     ]
    }
   ],
   "source": [
    "# 定义起点POI为i，终点POI为j，耗时阈值T为60分钟\n",
    "i = '起点POI'\n",
    "j = '终点POI'\n",
    "T = 60\n",
    "\n",
    "# 计算(i和j之间耗时小于60的数据)的数量\n",
    "filtered_count = filtered_results_df.groupby([i, j])['出租车ID'].count().reset_index(name='filtered_count')\n",
    "\n",
    "# 计算(i和j之间全部的数据)的数量\n",
    "total_count = results_df.groupby([i, j])['出租车ID'].count().reset_index(name='total_count')\n",
    "\n",
    "# 合并两个数据框以便计算概率\n",
    "merged_df = pd.merge(filtered_count, total_count, on=[i, j])\n",
    "\n",
    "# 计算概率Z(i,j,T)\n",
    "merged_df['Z(i,j,T)'] = merged_df['filtered_count'] / merged_df['total_count']\n",
    "\n",
    "# 显示结果\n",
    "print(merged_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
